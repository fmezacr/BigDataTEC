{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Machine Learning Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se llevará a cabo un ejercicio básico de clasificación, más adelante se abordarán otros detalles relacionados con aprendizaje supervisado y deep learning en el ámbito de Big Data.\n",
    "\n",
    "Usaremos un conjunto de datos el cual representa información de clientes que han aplicado a préstamos bancarios, nuestra clase o salida del sistema de ML será un dato binario que indica si basado en los features, al cliente se le otorgo o no el préstamo.\n",
    "\n",
    "En terminos generales y a manera de repaso, las etapas por las que haremos el recorrido son:\n",
    "\n",
    "* Cargar el set de datos\n",
    "* Llevar a cabo un analisis exploratorio de los datos.\n",
    "* Ejecutar alguna transformacion en caso de que sea necesaria.\n",
    "* Dividir los datos en *training* y *testing*.\n",
    "* Entrenar y evaluar el modelo.\n",
    "* Llevar a cabo cualquier ajuste de hyper-parámetros.\n",
    "* Construir el modelo final con los mejores parámetros.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para empezar, inicializamos el objeto SPARK:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('binary_class').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguidamente usamos SPARK para cargar el conjunto de datos y crear la estrucutra de datos Spark \"DataFrame\" :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the dataset\n",
    "df=spark.read.csv('classification_data.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguidamente, llevamos a cabo una exploración de los datos.\n",
    "\n",
    "Empezamos validando el tamaño de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46751, 12)\n"
     ]
    }
   ],
   "source": [
    "#check the shape of the data \n",
    "print((df.count(),len(df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploramos los feautures y clases, en este caso, la clase binaria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_id: string (nullable = true)\n",
      " |-- loan_purpose: string (nullable = true)\n",
      " |-- is_first_loan: integer (nullable = true)\n",
      " |-- total_credit_card_limit: integer (nullable = true)\n",
      " |-- avg_percentage_credit_card_limit_used_last_year: double (nullable = true)\n",
      " |-- saving_amount: integer (nullable = true)\n",
      " |-- checking_amount: integer (nullable = true)\n",
      " |-- is_employed: integer (nullable = true)\n",
      " |-- yearly_salary: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- dependent_number: integer (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#printSchema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loan_id',\n",
       " 'loan_purpose',\n",
       " 'is_first_loan',\n",
       " 'total_credit_card_limit',\n",
       " 'avg_percentage_credit_card_limit_used_last_year',\n",
       " 'saving_amount',\n",
       " 'checking_amount',\n",
       " 'is_employed',\n",
       " 'yearly_salary',\n",
       " 'age',\n",
       " 'dependent_number',\n",
       " 'label']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of columns in dataset\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos los datos en forma de Spark DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-------------+-----------------------+-----------------------------------------------+-------------+---------------+-----------+-------------+---+----------------+-----+\n",
      "|loan_id|loan_purpose|is_first_loan|total_credit_card_limit|avg_percentage_credit_card_limit_used_last_year|saving_amount|checking_amount|is_employed|yearly_salary|age|dependent_number|label|\n",
      "+-------+------------+-------------+-----------------------+-----------------------------------------------+-------------+---------------+-----------+-------------+---+----------------+-----+\n",
      "|    A_1|    personal|            1|                   7900|                                            0.8|         1103|           6393|          1|        16400| 42|               4|    0|\n",
      "|    A_2|    personal|            0|                   3300|                                           0.29|         2588|            832|          1|        75500| 56|               1|    0|\n",
      "|    A_3|    personal|            0|                   7600|                                            0.9|         1651|           8868|          1|        59000| 46|               1|    0|\n",
      "|    A_4|    personal|            1|                   3400|                                           0.38|         1269|           6863|          1|        26000| 55|               8|    0|\n",
      "|    A_5|   emergency|            0|                   2600|                                           0.89|         1310|           3423|          1|         9700| 41|               4|    1|\n",
      "|    A_6|  operations|            0|                   7600|                                           0.51|         1040|           2406|          1|        22900| 52|               0|    0|\n",
      "|    A_7|  operations|            1|                   6900|                                           0.82|         2408|           5556|          1|        34800| 48|               4|    0|\n",
      "|    A_8|    personal|            0|                   5700|                                           0.56|         1933|           4139|          1|        32500| 64|               2|    0|\n",
      "|    A_9|    personal|            1|                   3400|                                           0.95|         3866|           4131|          1|        13300| 23|               3|    0|\n",
      "|   A_10|    personal|            0|                   2900|                                           0.91|           88|           2725|          1|        21100| 52|               1|    1|\n",
      "|   A_11|      others|            1|                   4900|                                           0.56|         1306|           2341|          1|        18300| 36|               6|    0|\n",
      "|   A_12|  operations|            0|                   7900|                                           0.52|         1077|            935|          1|        34200| 62|               7|    0|\n",
      "|   A_13|   emergency|            1|                   2500|                                           0.86|          873|           1846|          1|        26100| 49|               8|    1|\n",
      "|   A_14|    property|            1|                   3000|                                           0.78|          699|           5315|          1|        27800| 33|               8|    0|\n",
      "|   A_15|      others|            1|                   3000|                                           0.92|         1358|            661|          0|            0| 47|               3|    1|\n",
      "|   A_16|   emergency|            0|                   2900|                                           0.75|         1301|           4074|          1|        46200| 55|               8|    0|\n",
      "|   A_17|    personal|            0|                   4800|                                           0.22|          955|           1359|          1|        41400| 40|               1|    0|\n",
      "|   A_19|   emergency|            1|                   3700|                                           0.93|         1501|           1716|          1|        39500| 32|               4|    1|\n",
      "|   A_20|  operations|            0|                   4600|                                           0.38|          348|           2408|          0|            0| 46|               8|    1|\n",
      "|   A_21|    personal|            0|                   5400|                                            0.6|          692|            846|          1|        69400| 47|               1|    0|\n",
      "+-------+------------+-------------+-----------------------+-----------------------------------------------+-------------+---------------+-----------+-------------+---+----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#view the data\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el fin de tener una mejor vista de los datos en términos del formato y orden, podemos hacer la misma visualización anterior, pero esta vez en forma de Pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_id</th>\n",
       "      <th>loan_purpose</th>\n",
       "      <th>is_first_loan</th>\n",
       "      <th>total_credit_card_limit</th>\n",
       "      <th>avg_percentage_credit_card_limit_used_last_year</th>\n",
       "      <th>saving_amount</th>\n",
       "      <th>checking_amount</th>\n",
       "      <th>is_employed</th>\n",
       "      <th>yearly_salary</th>\n",
       "      <th>age</th>\n",
       "      <th>dependent_number</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A_1</td>\n",
       "      <td>personal</td>\n",
       "      <td>1</td>\n",
       "      <td>7900</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1103</td>\n",
       "      <td>6393</td>\n",
       "      <td>1</td>\n",
       "      <td>16400</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A_2</td>\n",
       "      <td>personal</td>\n",
       "      <td>0</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2588</td>\n",
       "      <td>832</td>\n",
       "      <td>1</td>\n",
       "      <td>75500</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_3</td>\n",
       "      <td>personal</td>\n",
       "      <td>0</td>\n",
       "      <td>7600</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1651</td>\n",
       "      <td>8868</td>\n",
       "      <td>1</td>\n",
       "      <td>59000</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A_4</td>\n",
       "      <td>personal</td>\n",
       "      <td>1</td>\n",
       "      <td>3400</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1269</td>\n",
       "      <td>6863</td>\n",
       "      <td>1</td>\n",
       "      <td>26000</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A_5</td>\n",
       "      <td>emergency</td>\n",
       "      <td>0</td>\n",
       "      <td>2600</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1310</td>\n",
       "      <td>3423</td>\n",
       "      <td>1</td>\n",
       "      <td>9700</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  loan_id loan_purpose  is_first_loan  total_credit_card_limit  \\\n",
       "0     A_1     personal              1                     7900   \n",
       "1     A_2     personal              0                     3300   \n",
       "2     A_3     personal              0                     7600   \n",
       "3     A_4     personal              1                     3400   \n",
       "4     A_5    emergency              0                     2600   \n",
       "\n",
       "   avg_percentage_credit_card_limit_used_last_year  saving_amount  \\\n",
       "0                                             0.80           1103   \n",
       "1                                             0.29           2588   \n",
       "2                                             0.90           1651   \n",
       "3                                             0.38           1269   \n",
       "4                                             0.89           1310   \n",
       "\n",
       "   checking_amount  is_employed  yearly_salary  age  dependent_number  label  \n",
       "0             6393            1          16400   42                 4      0  \n",
       "1              832            1          75500   56                 1      0  \n",
       "2             8868            1          59000   46                 1      0  \n",
       "3             6863            1          26000   55                 8      0  \n",
       "4             3423            1           9700   41                 4      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutamos un análisis estadístico de los datos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------+------------------+-----------------------+-----------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|summary|loan_id|loan_purpose|     is_first_loan|total_credit_card_limit|avg_percentage_credit_card_limit_used_last_year|     saving_amount|   checking_amount|       is_employed|     yearly_salary|               age|  dependent_number|              label|\n",
      "+-------+-------+------------+------------------+-----------------------+-----------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|  count|  46751|       46751|             46751|                  46751|                                          46751|             46751|             46751|             46751|             46751|             46751|             46751|              46751|\n",
      "|   mean|   null|        null|0.5414429637868708|      4615.304485465552|                              0.700091121045545| 2037.636585313683|3520.6714294881394|0.9173279715941905| 29527.62079955509| 41.53979594019379|3.7448396825736348|0.34653804196701676|\n",
      "| stddev|   null|        null|0.4982848498677868|      1890.194453628314|                             0.1777288093267152|1498.6710906030362|2160.9332423713727|0.2753887911928983|16149.757703029438|12.817646350266434|2.6191527902107667|0.47587211651314887|\n",
      "|    min|    A_1|   emergency|                 0|                    500|                                            0.0|                 0|                 0|                 0|                 0|                18|                 0|                  0|\n",
      "|    max| A_9999|    property|                 1|                  13500|                                           1.09|             10641|             13165|                 1|             97200|                79|                 8|                  1|\n",
      "+-------+-------+------------+------------------+-----------------------+-----------------------------------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exploratory Data Analysis\n",
    "df.describe().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validamos la distribución de las cantidades en la salida (clase):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|16201|\n",
      "|    0|30550|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos como un poco más del 1/3 de los clientes obtuvieron la aprobación de su solicitid de préstamo.\n",
    "\n",
    "Y cuáles serán los propósitos de préstamos más comunes?, el siguiente comando nos brinda esa información:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|loan_purpose|count|\n",
      "+------------+-----+\n",
      "|      others| 6763|\n",
      "|   emergency| 7562|\n",
      "|    property|11388|\n",
      "|  operations|10580|\n",
      "|    personal|10458|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('loan_purpose').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente, hacemos una validación de los datos que requieran de algun tipo de transformacion, por ejemplo, en nuestro caso notamos que casi todas las features relevantes son numericas, con excepcion de *\"loan_purpose\"*, la cual represneta un feature de relevancia pero que requiere transformación de tipo One Hot Encoder: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting categorical data to numerical form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_purpose_indexer = StringIndexer(inputCol=\"loan_purpose\", outputCol=\"loan_index\").fit(df)\n",
    "df = loan_purpose_indexer.transform(df)\n",
    "loan_encoder = OneHotEncoder(inputCol=\"loan_index\", outputCol=\"loan_purpose_vec\")\n",
    "df = loan_encoder.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------------+\n",
      "|loan_purpose|loan_index|loan_purpose_vec|\n",
      "+------------+----------+----------------+\n",
      "|personal    |2.0       |(4,[2],[1.0])   |\n",
      "|personal    |2.0       |(4,[2],[1.0])   |\n",
      "|personal    |2.0       |(4,[2],[1.0])   |\n",
      "|personal    |2.0       |(4,[2],[1.0])   |\n",
      "|emergency   |3.0       |(4,[3],[1.0])   |\n",
      "|operations  |1.0       |(4,[1],[1.0])   |\n",
      "|operations  |1.0       |(4,[1],[1.0])   |\n",
      "|personal    |2.0       |(4,[2],[1.0])   |\n",
      "|personal    |2.0       |(4,[2],[1.0])   |\n",
      "|personal    |2.0       |(4,[2],[1.0])   |\n",
      "|others      |4.0       |(4,[],[])       |\n",
      "|operations  |1.0       |(4,[1],[1.0])   |\n",
      "|emergency   |3.0       |(4,[3],[1.0])   |\n",
      "|property    |0.0       |(4,[0],[1.0])   |\n",
      "|others      |4.0       |(4,[],[])       |\n",
      "|emergency   |3.0       |(4,[3],[1.0])   |\n",
      "|personal    |2.0       |(4,[2],[1.0])   |\n",
      "|emergency   |3.0       |(4,[3],[1.0])   |\n",
      "|operations  |1.0       |(4,[1],[1.0])   |\n",
      "|personal    |2.0       |(4,[2],[1.0])   |\n",
      "+------------+----------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['loan_purpose','loan_index','loan_purpose_vec']).show(20,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora usamos \"VectorAssembler\" para crear un único vector de features y clase, para ser usado por nuestro modelo de entrenamiento:\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validamos las columnas en el DF despu´s de la aplicación del OHE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loan_id',\n",
       " 'loan_purpose',\n",
       " 'is_first_loan',\n",
       " 'total_credit_card_limit',\n",
       " 'avg_percentage_credit_card_limit_used_last_year',\n",
       " 'saving_amount',\n",
       " 'checking_amount',\n",
       " 'is_employed',\n",
       " 'yearly_salary',\n",
       " 'age',\n",
       " 'dependent_number',\n",
       " 'label',\n",
       " 'loan_index',\n",
       " 'loan_purpose_vec']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assembler = VectorAssembler(inputCols=['is_first_loan',\n",
    " 'total_credit_card_limit',\n",
    " 'avg_percentage_credit_card_limit_used_last_year',\n",
    " 'saving_amount',\n",
    " 'checking_amount',\n",
    " 'is_employed',\n",
    " 'yearly_salary',\n",
    " 'age',\n",
    " 'dependent_number',\n",
    " 'loan_purpose_vec'], outputCol=\"features\")\n",
    "df = df_assembler.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisamos el Schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_id: string (nullable = true)\n",
      " |-- loan_purpose: string (nullable = true)\n",
      " |-- is_first_loan: integer (nullable = true)\n",
      " |-- total_credit_card_limit: integer (nullable = true)\n",
      " |-- avg_percentage_credit_card_limit_used_last_year: double (nullable = true)\n",
      " |-- saving_amount: integer (nullable = true)\n",
      " |-- checking_amount: integer (nullable = true)\n",
      " |-- is_employed: integer (nullable = true)\n",
      " |-- yearly_salary: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- dependent_number: integer (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- loan_index: double (nullable = false)\n",
      " |-- loan_purpose_vec: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos los primeros 20 resultados, nótese el dato categórico como aparece ahora ya vectorizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------+-----+\n",
      "|features                                                            |label|\n",
      "+--------------------------------------------------------------------+-----+\n",
      "|[1.0,7900.0,0.8,1103.0,6393.0,1.0,16400.0,42.0,4.0,0.0,0.0,1.0,0.0] |0    |\n",
      "|[0.0,3300.0,0.29,2588.0,832.0,1.0,75500.0,56.0,1.0,0.0,0.0,1.0,0.0] |0    |\n",
      "|[0.0,7600.0,0.9,1651.0,8868.0,1.0,59000.0,46.0,1.0,0.0,0.0,1.0,0.0] |0    |\n",
      "|[1.0,3400.0,0.38,1269.0,6863.0,1.0,26000.0,55.0,8.0,0.0,0.0,1.0,0.0]|0    |\n",
      "|[0.0,2600.0,0.89,1310.0,3423.0,1.0,9700.0,41.0,4.0,0.0,0.0,0.0,1.0] |1    |\n",
      "|[0.0,7600.0,0.51,1040.0,2406.0,1.0,22900.0,52.0,0.0,0.0,1.0,0.0,0.0]|0    |\n",
      "|[1.0,6900.0,0.82,2408.0,5556.0,1.0,34800.0,48.0,4.0,0.0,1.0,0.0,0.0]|0    |\n",
      "|[0.0,5700.0,0.56,1933.0,4139.0,1.0,32500.0,64.0,2.0,0.0,0.0,1.0,0.0]|0    |\n",
      "|[1.0,3400.0,0.95,3866.0,4131.0,1.0,13300.0,23.0,3.0,0.0,0.0,1.0,0.0]|0    |\n",
      "|[0.0,2900.0,0.91,88.0,2725.0,1.0,21100.0,52.0,1.0,0.0,0.0,1.0,0.0]  |1    |\n",
      "|[1.0,4900.0,0.56,1306.0,2341.0,1.0,18300.0,36.0,6.0,0.0,0.0,0.0,0.0]|0    |\n",
      "|[0.0,7900.0,0.52,1077.0,935.0,1.0,34200.0,62.0,7.0,0.0,1.0,0.0,0.0] |0    |\n",
      "|[1.0,2500.0,0.86,873.0,1846.0,1.0,26100.0,49.0,8.0,0.0,0.0,0.0,1.0] |1    |\n",
      "|[1.0,3000.0,0.78,699.0,5315.0,1.0,27800.0,33.0,8.0,1.0,0.0,0.0,0.0] |0    |\n",
      "|(13,[0,1,2,3,4,7,8],[1.0,3000.0,0.92,1358.0,661.0,47.0,3.0])        |1    |\n",
      "|[0.0,2900.0,0.75,1301.0,4074.0,1.0,46200.0,55.0,8.0,0.0,0.0,0.0,1.0]|0    |\n",
      "|[0.0,4800.0,0.22,955.0,1359.0,1.0,41400.0,40.0,1.0,0.0,0.0,1.0,0.0] |0    |\n",
      "|[1.0,3700.0,0.93,1501.0,1716.0,1.0,39500.0,32.0,4.0,0.0,0.0,0.0,1.0]|1    |\n",
      "|(13,[1,2,3,4,7,8,10],[4600.0,0.38,348.0,2408.0,46.0,8.0,1.0])       |1    |\n",
      "|[0.0,5400.0,0.6,692.0,846.0,1.0,69400.0,47.0,1.0,0.0,0.0,1.0,0.0]   |0    |\n",
      "+--------------------------------------------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['features','label']).show(20,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos ahora a contruir el modelo de aprendizaje automático:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select data for building model\n",
    "model_df=df.select(['features','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partimos el conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data \n",
    "training_df,test_df = model_df.randomSplit([0.75,0.25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploramos los conjuntos de entrenamiento y pruebas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34970"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|12137|\n",
      "|    0|22833|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_df.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11781"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1| 4064|\n",
      "|    0| 7717|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos Regresión Logística.\n",
    "\n",
    "**ENTRENAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg=LogisticRegression().fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_summary=log_reg.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8933943380040035"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_summary.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9584570193368336"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_summary.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9229951733604924, 0.8394284330346331]\n"
     ]
    }
   ],
   "source": [
    "print(lr_summary.precisionByLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9128892392589673, 0.8567191233418472]\n"
     ]
    }
   ],
   "source": [
    "print(lr_summary.recallByLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(13,[0,1,2,3,4,7]...|    1|[-1.5737970518925...|[0.17167576548564...|       1.0|\n",
      "|(13,[0,1,2,3,4,7,...|    1|[-4.5573852767910...|[0.01038056372090...|       1.0|\n",
      "|(13,[0,1,2,3,4,7,...|    1|[-6.1031900223565...|[0.00223073700819...|       1.0|\n",
      "|(13,[0,1,2,3,4,7,...|    1|[-6.6930010076807...|[0.00123802266475...|       1.0|\n",
      "|(13,[0,1,2,3,4,7,...|    1|[-6.7192708021125...|[0.00120596223900...|       1.0|\n",
      "|(13,[0,1,2,3,4,7,...|    1|[-5.5200562402430...|[0.00398964165953...|       1.0|\n",
      "|(13,[0,1,2,3,4,7,...|    1|[-6.3680258628245...|[0.00171260455519...|       1.0|\n",
      "|(13,[0,1,2,3,4,7,...|    1|[-5.1219420736524...|[0.00592906479907...|       1.0|\n",
      "|(13,[0,1,2,3,4,7,...|    1|[-3.6564198944700...|[0.02517467199970...|       1.0|\n",
      "|(13,[0,1,2,3,4,7,...|    0|[-1.2380555902642...|[0.22477461972547...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = log_reg.transform(test_df)\n",
    "predictions.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TESTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = log_reg.transform(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = log_reg.evaluate(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8950853068500128"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predictions.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.895524739623859"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predictions.weightedPrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9157703770895426, 0.8558070866141733]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predictions.recallByLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9234287207630995, 0.8425387596899225]\n"
     ]
    }
   ],
   "source": [
    "print(model_predictions.precisionByLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9601851138553903"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predictions.areaUnderROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                        A que corresponde el caso? Underfitting, Fitting, Overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validamos el caso ahora del ajuste de hyper-parámetros, para esto recurrimos al uso de un método mas avanzado como lo seria RandomForest. Primeramente entrenamos y probamos con los hyper-parámetros por defecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf_model = rf.fit(training_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = rf_model.transform(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los parámetros a probar se selecciona **maxDepth**, **maxBins** y **numTrees**, se aplica cross-validation para determinar el mejor modelo y se usa además five-fold cross-validation (4 partes para entrenamiento y 1 para testing).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "         ****DEPENDIENDO DEL PODER DE COMPUTO, EL TIEMPO DE EJECUCION PUEDE TOMAR ALREDEDOR DE UNA HORA****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 47.33 min / 2839.69 sec\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import time\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.maxDepth, [5,10,20,25,30])\n",
    "             .addGrid(rf.maxBins, [20,30,40 ])\n",
    "             .addGrid(rf.numTrees, [5, 20,50])\n",
    "             .build())\n",
    "cv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "cv_model = cv.fit(training_df)\n",
    "\n",
    "end = time.time()\n",
    "m = (end - start)/60\n",
    "m = round(m, 2)\n",
    "s = (end - start)\n",
    "s = round(s, 2)\n",
    "print(f\"Time: {m} min / {s} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_model = cv_model.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutamos testing, ahora con el mejor modelo obtenido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for entire dataset\n",
    "model_predictions = best_rf_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos=model_predictions.filter(model_predictions['label']==1).filter(model_predictions['prediction']==1).count()\n",
    "actual_pos=model_predictions.filter(model_predictions['label']==1).count()\n",
    "pred_pos=model_predictions.filter(model_predictions['prediction']==1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9023129921259843"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recall \n",
    "float(true_pos)/(actual_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.848646146725295"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Precision on test Data \n",
    "float(true_pos)/(pred_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recordar que era recall y validar si puedo tener un porcentaje de accuracy???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1.0, 3600.0, 0.88, 1599.0, 3470.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[9.082473629848312, 40.91752637015169]</td>\n",
       "      <td>[0.18164947259696626, 0.8183505274030338]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.0, 500.0, 0.78, 779.0, 3461.0, 0.0, 0.0, 45...</td>\n",
       "      <td>1</td>\n",
       "      <td>[2.2665492292811757, 47.73345077071883]</td>\n",
       "      <td>[0.045330984585623506, 0.9546690154143765]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1.0, 500.0, 0.89, 1208.0, 1735.0, 0.0, 0.0, 3...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.1966448465429012, 48.80335515345711]</td>\n",
       "      <td>[0.023932896930858018, 0.9760671030691419]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1.0, 700.0, 0.72, 1234.0, 437.0, 0.0, 0.0, 32...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.4666908845655189, 48.5333091154345]</td>\n",
       "      <td>[0.029333817691310368, 0.9706661823086897]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1.0, 800.0, 0.57, 822.0, 46.0, 0.0, 0.0, 43.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>[2.450566764893948, 47.549433235106065]</td>\n",
       "      <td>[0.04901133529787895, 0.9509886647021211]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1.0, 900.0, 0.76, 1165.0, 1136.0, 0.0, 0.0, 5...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.3702831467895977, 48.62971685321043]</td>\n",
       "      <td>[0.027405662935791938, 0.9725943370642081]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(1.0, 1100.0, 1.04, 1093.0, 1795.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.1796400060645191, 48.820359993935504]</td>\n",
       "      <td>[0.023592800121290374, 0.9764071998787097]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1.0, 1200.0, 1.06, 1755.0, 2056.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[2.604731487311582, 47.39526851268844]</td>\n",
       "      <td>[0.052094629746231615, 0.9479053702537684]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(1.0, 1300.0, 0.79, 1886.0, 1977.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.3295840411165634, 48.67041595888343]</td>\n",
       "      <td>[0.026591680822331272, 0.9734083191776688]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(1.0, 1500.0, 0.79, 545.0, 7686.0, 0.0, 0.0, 3...</td>\n",
       "      <td>0</td>\n",
       "      <td>[42.78919515850288, 7.210804841497128]</td>\n",
       "      <td>[0.8557839031700575, 0.14421609682994255]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(1.0, 1500.0, 0.86, 896.0, 1043.0, 0.0, 0.0, 6...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.1538379404709782, 48.84616205952904]</td>\n",
       "      <td>[0.023076758809419555, 0.9769232411905804]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(1.0, 1600.0, 0.45, 671.0, 808.0, 0.0, 0.0, 40...</td>\n",
       "      <td>1</td>\n",
       "      <td>[2.6718038215689663, 47.32819617843105]</td>\n",
       "      <td>[0.05343607643137931, 0.9465639235686207]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(1.0, 1600.0, 0.66, 429.0, 2154.0, 0.0, 0.0, 3...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.871272371323986, 48.12872762867603]</td>\n",
       "      <td>[0.03742544742647971, 0.9625745525735203]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(1.0, 1900.0, 0.92, 297.0, 1170.0, 0.0, 0.0, 2...</td>\n",
       "      <td>1</td>\n",
       "      <td>[2.11805432183998, 47.88194567816003]</td>\n",
       "      <td>[0.04236108643679959, 0.9576389135632004]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(1.0, 2100.0, 0.81, 743.0, 776.0, 0.0, 0.0, 39...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.1966448465429012, 48.80335515345711]</td>\n",
       "      <td>[0.023932896930858018, 0.9760671030691419]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(1.0, 2100.0, 0.86, 1343.0, 3324.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.6132972063384843, 48.38670279366153]</td>\n",
       "      <td>[0.032265944126769676, 0.9677340558732302]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(1.0, 2100.0, 0.93, 716.0, 1936.0, 0.0, 0.0, 4...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.1858704523471955, 48.814129547652826]</td>\n",
       "      <td>[0.0237174090469439, 0.9762825909530561]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(1.0, 2100.0, 0.93, 758.0, 1419.0, 0.0, 0.0, 3...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.1938358577788561, 48.80616414222116]</td>\n",
       "      <td>[0.023876717155577116, 0.9761232828444228]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(1.0, 2100.0, 0.99, 1022.0, 1663.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.4132833988736149, 48.586716601126405]</td>\n",
       "      <td>[0.028265667977472285, 0.9717343320225277]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(1.0, 2100.0, 1.06, 481.0, 876.0, 0.0, 0.0, 67...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.3248075351783397, 48.67519246482168]</td>\n",
       "      <td>[0.026496150703566788, 0.9735038492964333]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             features  label  \\\n",
       "0   (1.0, 3600.0, 0.88, 1599.0, 3470.0, 0.0, 0.0, ...      1   \n",
       "1   (1.0, 500.0, 0.78, 779.0, 3461.0, 0.0, 0.0, 45...      1   \n",
       "2   (1.0, 500.0, 0.89, 1208.0, 1735.0, 0.0, 0.0, 3...      1   \n",
       "3   (1.0, 700.0, 0.72, 1234.0, 437.0, 0.0, 0.0, 32...      1   \n",
       "4   (1.0, 800.0, 0.57, 822.0, 46.0, 0.0, 0.0, 43.0...      1   \n",
       "5   (1.0, 900.0, 0.76, 1165.0, 1136.0, 0.0, 0.0, 5...      1   \n",
       "6   (1.0, 1100.0, 1.04, 1093.0, 1795.0, 0.0, 0.0, ...      1   \n",
       "7   (1.0, 1200.0, 1.06, 1755.0, 2056.0, 0.0, 0.0, ...      1   \n",
       "8   (1.0, 1300.0, 0.79, 1886.0, 1977.0, 0.0, 0.0, ...      1   \n",
       "9   (1.0, 1500.0, 0.79, 545.0, 7686.0, 0.0, 0.0, 3...      0   \n",
       "10  (1.0, 1500.0, 0.86, 896.0, 1043.0, 0.0, 0.0, 6...      1   \n",
       "11  (1.0, 1600.0, 0.45, 671.0, 808.0, 0.0, 0.0, 40...      1   \n",
       "12  (1.0, 1600.0, 0.66, 429.0, 2154.0, 0.0, 0.0, 3...      1   \n",
       "13  (1.0, 1900.0, 0.92, 297.0, 1170.0, 0.0, 0.0, 2...      1   \n",
       "14  (1.0, 2100.0, 0.81, 743.0, 776.0, 0.0, 0.0, 39...      1   \n",
       "15  (1.0, 2100.0, 0.86, 1343.0, 3324.0, 0.0, 0.0, ...      1   \n",
       "16  (1.0, 2100.0, 0.93, 716.0, 1936.0, 0.0, 0.0, 4...      1   \n",
       "17  (1.0, 2100.0, 0.93, 758.0, 1419.0, 0.0, 0.0, 3...      1   \n",
       "18  (1.0, 2100.0, 0.99, 1022.0, 1663.0, 0.0, 0.0, ...      1   \n",
       "19  (1.0, 2100.0, 1.06, 481.0, 876.0, 0.0, 0.0, 67...      1   \n",
       "\n",
       "                               rawPrediction  \\\n",
       "0     [9.082473629848312, 40.91752637015169]   \n",
       "1    [2.2665492292811757, 47.73345077071883]   \n",
       "2    [1.1966448465429012, 48.80335515345711]   \n",
       "3     [1.4666908845655189, 48.5333091154345]   \n",
       "4    [2.450566764893948, 47.549433235106065]   \n",
       "5    [1.3702831467895977, 48.62971685321043]   \n",
       "6   [1.1796400060645191, 48.820359993935504]   \n",
       "7     [2.604731487311582, 47.39526851268844]   \n",
       "8    [1.3295840411165634, 48.67041595888343]   \n",
       "9     [42.78919515850288, 7.210804841497128]   \n",
       "10   [1.1538379404709782, 48.84616205952904]   \n",
       "11   [2.6718038215689663, 47.32819617843105]   \n",
       "12    [1.871272371323986, 48.12872762867603]   \n",
       "13     [2.11805432183998, 47.88194567816003]   \n",
       "14   [1.1966448465429012, 48.80335515345711]   \n",
       "15   [1.6132972063384843, 48.38670279366153]   \n",
       "16  [1.1858704523471955, 48.814129547652826]   \n",
       "17   [1.1938358577788561, 48.80616414222116]   \n",
       "18  [1.4132833988736149, 48.586716601126405]   \n",
       "19   [1.3248075351783397, 48.67519246482168]   \n",
       "\n",
       "                                   probability  prediction  \n",
       "0    [0.18164947259696626, 0.8183505274030338]         1.0  \n",
       "1   [0.045330984585623506, 0.9546690154143765]         1.0  \n",
       "2   [0.023932896930858018, 0.9760671030691419]         1.0  \n",
       "3   [0.029333817691310368, 0.9706661823086897]         1.0  \n",
       "4    [0.04901133529787895, 0.9509886647021211]         1.0  \n",
       "5   [0.027405662935791938, 0.9725943370642081]         1.0  \n",
       "6   [0.023592800121290374, 0.9764071998787097]         1.0  \n",
       "7   [0.052094629746231615, 0.9479053702537684]         1.0  \n",
       "8   [0.026591680822331272, 0.9734083191776688]         1.0  \n",
       "9    [0.8557839031700575, 0.14421609682994255]         0.0  \n",
       "10  [0.023076758809419555, 0.9769232411905804]         1.0  \n",
       "11   [0.05343607643137931, 0.9465639235686207]         1.0  \n",
       "12   [0.03742544742647971, 0.9625745525735203]         1.0  \n",
       "13   [0.04236108643679959, 0.9576389135632004]         1.0  \n",
       "14  [0.023932896930858018, 0.9760671030691419]         1.0  \n",
       "15  [0.032265944126769676, 0.9677340558732302]         1.0  \n",
       "16    [0.0237174090469439, 0.9762825909530561]         1.0  \n",
       "17  [0.023876717155577116, 0.9761232828444228]         1.0  \n",
       "18  [0.028265667977472285, 0.9717343320225277]         1.0  \n",
       "19  [0.026496150703566788, 0.9735038492964333]         1.0  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predictions.limit(20).toPandas().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
